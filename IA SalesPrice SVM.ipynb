{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bc4d7c8e-aea3-416c-adb8-63fac3bd3e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Y Réel       Y Prédit\n",
      "0  374000  344327.089818\n",
      "1  232000  258809.319738\n",
      "2  173000  181852.155022\n",
      "3  128500  126236.584265\n",
      "4  128500  133335.561450\n",
      "14.84829646884698\n",
      "Les prédictions SVM ont été sauvegardées dans 'test_predictions_svm.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Chargement des données\n",
    "data_train = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Liste des colonnes qu'on veut garder en valeur numérique : \n",
    "numeric_columns = ['OverallQual','OverallCond','YearBuilt','YearRemodAdd','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','YrSold']\n",
    "#mainFeatures = ['OverallQual', 'TotRmsAbvGrd', 'LotArea', 'GrLivArea', 'YrSold']\n",
    "mainFeatures = ['OverallQual','GrLivArea','YrSold']\n",
    "target = 'SalePrice'\n",
    "\n",
    "# Prétraitement des données textuelles : One-Hot Encoding pour les colonnes catégorielles\n",
    "data_train = pd.get_dummies(data_train, drop_first=True)  # `drop_first=True` pour éviter la multicolinéarité\n",
    "data_test = pd.get_dummies(data_test, drop_first=True)\n",
    "data_train, data_test = data_train.align(data_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Forcer la conversion des colonnes numériques en float\n",
    "data_train[numeric_columns] = data_train[numeric_columns].astype(float)\n",
    "data_test[numeric_columns] = data_test[numeric_columns].astype(float)\n",
    "\n",
    "#On remplace les NaN values par la moyenne de la colonne)\n",
    "data_train.fillna(data_train.mean(), inplace=True)\n",
    "data_test.fillna(data_test.mean(), inplace=True)\n",
    "\n",
    "# Séparation des données en X = Features et y = Target\n",
    "X = data_train.drop(target, axis=1).values  # Sélectionner les features de cette combinaison\n",
    "#X = data_train[mainFeatures].values # Sélectionner les features de cette combinaison\n",
    "y = data_train[target].values\n",
    "       \n",
    "# Diviser les données en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#On entraine les données sur le Log des prix, pour avoir une distribution des prix moins centrée autour de la moyenne et améliorer l'apprentissage\n",
    "y_train_log = np.log1p(y_train)  # Transformation log1p (log(x+1)) pour éviter problèmes avec les 0\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "#Standardisation des données (avec le même scaler pour les données de Test et de Train)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "#Boucle utilisée pour tester le nombre de features optimal à sélectionner pour mon modèle : \n",
    "\"\"\"\n",
    "# Dictionnaire pour stocker les résultats\n",
    "results = []\n",
    "i = 5\n",
    "\n",
    "while i <= 20 :\n",
    "    \n",
    "    print(f\"Entraînement avec les {i} best features :\")\n",
    "    errors = []  # Liste pour stocker l'erreur de chaque essai (30 essais)\n",
    "\n",
    "    for a in range(30) :\n",
    "        selector = RFE(lasso, n_features_to_select=i)  # Sélectionner les i meilleures caractéristiques\n",
    "        X_train_selected = selector.fit_transform(X_train_scaled, y_train_log)\n",
    "        X_test_selected = selector.transform(X_test_scaled)\n",
    "        model_svm.fit(X_train_selected, y_train_log)\n",
    "\n",
    "        # Faire des prédictions sur les données de test\n",
    "        y_test_pred_log = model_svm.predict(X_test_selected)\n",
    "\n",
    "        # Inverser la transformation logarithmique pour obtenir les valeurs réelles\n",
    "        y_test_pred = np.expm1(y_test_pred_log)  # expm1 inverse log1p\n",
    "\n",
    "        # Calcul de l'erreur quadratique moyenne\n",
    "        mse = mean_squared_error(y_test, y_test_pred)\n",
    "        errMoy = 100 * (mse ** 0.5) * len(y_test) / sum(y_test)\n",
    "\n",
    "        errors.append(errMoy)\n",
    "\n",
    "    # Calculer l'erreur moyenne sur les 30 essais\n",
    "    mean_error = np.mean(errors)\n",
    "\n",
    "    # Sauvegarder les résultats\n",
    "    results.append((i, mean_error))\n",
    "\n",
    "    print(f\"ErrMoy moyenne de {mean_error}\")\n",
    "\n",
    "    i+=1\n",
    "\n",
    "# Trier les résultats par erreur moyenne croissante\n",
    "results.sort(key=lambda x: x[1])\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"\\nClassement par erreur moyenne en fct du nb de features sélectionnées :\")\n",
    "for i, mean_error in results:\n",
    "    print(f\"Nb features : {i} - Erreur moyenne : {mean_error:.2f}%\")  \n",
    "\"\"\"\n",
    "\n",
    "# Création et entraînement du modèle SVM\n",
    "model_svm = SVR(kernel='rbf')\n",
    "lasso = Lasso(alpha=0.01)  # Choisir un alpha faible pour ne pas trop pénaliser les coefficients\n",
    "selector = RFE(lasso, n_features_to_select=20)  # Sélectionner les 10 meilleures caractéristiques\n",
    "X_train_scaled = selector.fit_transform(X_train_scaled, y_train_log)\n",
    "X_test_scaled = selector.transform(X_test_scaled)\n",
    "model_svm.fit(X_train_scaled, y_train_log)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "y_test_pred_log = model_svm.predict(X_test_scaled)\n",
    "\n",
    "# Inverser la transformation logarithmique pour obtenir les valeurs réelles\n",
    "y_test_pred = np.expm1(y_test_pred_log)  # expm1 inverse log1p\n",
    "\n",
    " # Calcul de l'erreur quadratique moyenne\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "errMoy = 100 * (mse ** 0.5) * len(y_test) / sum(y_test)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Y Réel': y_test,    # Valeurs réelles (targets)\n",
    "    'Y Prédit': y_test_pred   # Valeurs prédites\n",
    "})\n",
    "\n",
    "print(comparison_df.head())\n",
    "print(errMoy)\n",
    "\n",
    "#Application du modèle sur données de validation : \n",
    "# Définition et formattage des données X de validation\n",
    "X_valid = data_test.drop(target, axis=1).values  # Sélectionner les features de cette combinaison\n",
    "scaler_valid = StandardScaler()\n",
    "X_valid_scaled = scaler_valid.fit_transform(X_valid)\n",
    "X_valid_scaled = selector.transform(X_valid_scaled)\n",
    "\n",
    "#Prédiction à l'aide du modèle créé précédemment\n",
    "y_valid_pred_log = model_svm.predict(X_valid_scaled)\n",
    "\n",
    "# Inverser la transformation logarithmique pour obtenir les valeurs réelles\n",
    "y_valid_pred = np.expm1(y_valid_pred_log)  # expm1 inverse log1p\n",
    "\n",
    "# Créer un DataFrame avec l'ID et les résultats prédits\n",
    "predictions_df_svm = pd.DataFrame({\n",
    "    'Id': data_test['Id'],  # Garder la colonne 'Id' du fichier original\n",
    "    'SalePrice': y_valid_pred  # Ajouter la colonne 'SalePrice' avec les prédictions\n",
    "})\n",
    "\n",
    "# Sauvegarder le DataFrame dans un fichier CSV avec les deux colonnes\n",
    "predictions_df_svm.to_csv('test_predictions_svm.csv', index=False)\n",
    "\n",
    "print(\"Les prédictions SVM ont été sauvegardées dans 'test_predictions_svm.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c4f7e5-8102-4ab1-93a7-3b214bfa7d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a500bfc4-01c9-4746-88ad-0efdce2b94f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
